{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to scikit-learn\n",
    "\n",
    "Notes from a workshop given by Lukas Biewald, CEO Crowdflower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running in python2, include these at top of code to ensure compatibility with python3 code:\n",
    "```\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets:\n",
      "0    .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
      "1    @jessedee Know about @fludapp ? Awesome iPad/i...\n",
      "2    @swonderlin Can not wait for #iPad 2 also. The...\n",
      "3    @sxsw I hope this year's festival isn't as cra...\n",
      "4    @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
      "5    @teachntech00 New iPad Apps For #SpeechTherapy...\n",
      "6                                                  NaN\n",
      "7    #SXSW is just starting, #CTIA is around the co...\n",
      "Name: tweet_text, dtype: object\n",
      "Sentiments:\n",
      "0                      Negative emotion\n",
      "1                      Positive emotion\n",
      "2                      Positive emotion\n",
      "3                      Negative emotion\n",
      "4                      Positive emotion\n",
      "5    No emotion toward brand or product\n",
      "6    No emotion toward brand or product\n",
      "7                      Positive emotion\n",
      "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: object\n"
     ]
    }
   ],
   "source": [
    "target = df['is_there_an_emotion_directed_at_a_brand_or_product']\n",
    "text = df['tweet_text']\n",
    "\n",
    "print (\"Tweets:\")\n",
    "print (text[0:8])\n",
    "print (\"Sentiments:\")\n",
    "print (target[0:8])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating features from text with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Missing Data\n",
    "\n",
    "Notice there is a __`NaN`__ value on line six of the head of the tweets data. There is some missing data which was classified as __\"No emotion toward brand or product\"__ and that isn't useful for classifying anything. Let's drop those out here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fixed_text = text[text.notnull()]\n",
    "fixed_target = target[text.notnull()] # note getting rid of same lines in both Series based on null data in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(fixed_text)\n",
    "\n",
    "counts = count_vect.transform(fixed_text)\n",
    "\n",
    "print (count_vect.vocabulary_.get(u'iphone'))\n",
    "print (count_vect.transform([\"I love my iphone!!!\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    " NB has a bunch of parameters -- somewhat scary for those who haven't\n",
    " used it before. That said, Scikit-Learn mostly has sane defaults,\n",
    " and usually it's not necessary to modify them. Can also try to\n",
    " change a new algorithm, but usually it's not the best way to spend\n",
    " your time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"http://scikit-learn.org/stable/_static/ml_map.png\">\n",
    "Source: http://scikit-learn.org/stable/tutorial/machine_learning_map/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(counts, fixed_target)\n",
    "\n",
    "predictions = nb.predict(counts)\n",
    "print (sum(predictions == fixed_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(counts[0:6000], fixed_target[0:6000])\n",
    "\n",
    "predictions = nb.predict(counts[6000:9092])\n",
    "print (sum(predictions == fixed_target[6000:9092]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "from sklearn import cross_validation\n",
    "\n",
    "scores = cross_validation.cross_val_score(nb, counts, fixed_target, cv=10)\n",
    "print (scores)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "nb_dummy = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "nb_dummy.fit(counts[0:6000], fixed_target[0:6000])\n",
    "\n",
    "predictions = nb_dummy.predict(counts[6000:9092])\n",
    "print (sum(predictions == fixed_target[6000:9092]))\n",
    "\n",
    "from sklearn import cross_validation\n",
    "\n",
    "scores = cross_validation.cross_val_score(nb_dummy, counts, fixed_target, cv=10)\n",
    "print (scores)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "p = Pipeline(steps=[('counts', CountVectorizer()),\n",
    "                ('multinomialnb', MultinomialNB())])\n",
    "\n",
    "p.fit(fixed_text, fixed_target)\n",
    "print (p.predict([\"I love my iphone!\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Pipeline(steps=[('counts', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('multinomialnb', MultinomialNB())])\n",
    "\n",
    "p.fit(fixed_text, fixed_target)\n",
    "print (p.named_steps['counts'].vocabulary_.get(u'garage sale'))\n",
    "print (len(p.named_steps['counts'].vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Pipeline(steps=[('counts', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('multinomialnb', MultinomialNB())])\n",
    "\n",
    "p.fit(fixed_text, fixed_target)\n",
    "print (p.predict([\"I love my iphone!\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Pipeline(steps=[('counts', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('multinomialnb', MultinomialNB())])\n",
    "\n",
    "p.fit(fixed_text, fixed_target)\n",
    "\n",
    "from sklearn import cross_validation\n",
    "\n",
    "scores = cross_validation.cross_val_score(p, fixed_text, fixed_target, cv=10)\n",
    "print (scores)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "p = Pipeline(steps=[('counts', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('feature_selection', SelectKBest(chi2, k=10000)),\n",
    "                ('multinomialnb', MultinomialNB())])\n",
    "\n",
    "p.fit(fixed_text, fixed_target)\n",
    "\n",
    "from sklearn import cross_validation\n",
    "\n",
    "scores = cross_validation.cross_val_score(p, fixed_text, fixed_target, cv=10)\n",
    "print (scores)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Pipeline(steps=[('counts', CountVectorizer()),\n",
    "                ('feature_selection', SelectKBest(chi2)),\n",
    "                ('multinomialnb', MultinomialNB())])\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'counts__max_df': (0.5, 0.75, 1.0),\n",
    "    'counts__min_df': (1, 2, 3),\n",
    "    'counts__ngram_range': ((1,1), (1,2)),\n",
    "#    'feature_selection__k': (1000, 10000, 100000)\n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(p, parameters, n_jobs=1, verbose=1, cv=10)\n",
    "\n",
    "grid_search.fit(fixed_text, fixed_target)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusions and Further Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
